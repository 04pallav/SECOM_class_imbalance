{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One class SVM classification for an imbalanced data set\n",
    "\n",
    "Date created: Oct 10, 2016   \n",
    "Last modified: Oct 18, 2016  \n",
    "Tags: one-class SVM, Random Forest variable importance, imbalanced data set, anomaly detection, feature selection, semiconductor manufacturing data   \n",
    "About: for an imbalanced semicondutor manufacturing dataset, find explanatory variables with predictive power and build a classifier to detect failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [SECOM dataset](http://archive.ics.uci.edu/ml/datasets/SECOM) in the  [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml) is semicondutor manufacturing data. There are 1567 records, 590 anonymized features and 104 fails. This makes it an imbalanced with a 14:1 ratio of pass to fails. The process yield has a simple pass/fail response (encoded -1/1).\n",
    "\n",
    "<h4>Objective</h4>\n",
    "If the overall objective is to streamline the manufacturing process two things are needed: (i) a good classifier and (ii) feature selection. A streamlined feature set can not only lead to better prediction accuracy and data understanding but also optimize manufacturing resources.  \n",
    "For this exercise, we will look at: \n",
    "- the use of a one-class SVM for an imbalanced data set \n",
    "- reducing the number of features to improve classifier performance\n",
    " \n",
    "\n",
    "<h4>Methodology</h4>\n",
    "The [Variable Importance](http://www.statistik.uni-dortmund.de/useR-2008/slides/Strobl+Zeileis.pdf) is a byproduct of the random forest classifier construction. We will rank the features in order of importance and the first <i>x</i> ranked features will be used for the classifier.\n",
    "We will then use the one-class SVM (OCSVM) method to classify the data. In the OCSVM, a decision boundary is learned using only the majority class. The minority class data are outliers in this setup. \n",
    "\n",
    "<h4>Preprocessing</h4>\n",
    "The data represents measurements from a large number of processes or sensors; many of the records are missing -- 50-60% of an entire column in 4% of the cases. In addition some measurements are identical/constant and so not useful for prediction. We will remove those columns with high missing count or constant values.<br>\n",
    "For the random forest classifier, we will impute the remainaing missing values with the median for the column.\n",
    "For the OCSVM, we will additionally scale the data. We will use the <i>sklearn preprocessing</i> module for both imputing and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split as tts\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 1567 observations/rows and 590 variables/columns.\n",
      "The majority class has 1463 observations, minority class 104.\n",
      "The dataset is imbalanced. The ratio of majority class to minority class is 14:1.\n"
     ]
    }
   ],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data\"\n",
    "secom = pd.read_table(url, header=None, delim_whitespace=True)\n",
    "\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data\"\n",
    "y = pd.read_table(url, header=None, usecols=[0], squeeze=True, delim_whitespace=True)\n",
    "\n",
    "print 'The dataset has {} observations/rows and {} variables/columns.'\\\n",
    "       .format(secom.shape[0], secom.shape[1])\n",
    "print 'The majority class has {} observations, minority class {}.'\\\n",
    "      .format(y[y == -1].size, y[y == 1].size)\n",
    "print 'The dataset is imbalanced. \\\n",
    "The ratio of majority class to minority class is {}:1.'\\\n",
    "      .format(int(y[y == -1].size/y[y == 1].size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprocessing </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will process the missing values first, dropping columns which have a large number of missing values and imputing values for those that have only a few missing values. We will use <i>pandas</i> for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of columns after removing columns with missing data: 52\n",
      "No. of rows after removing rows with missing data: 0\n"
     ]
    }
   ],
   "source": [
    "# what if all the columns/rows with missing values were removed\n",
    "nmv = secom.dropna(axis=1)\n",
    "print 'No. of columns after removing columns with missing data: {}'\\\n",
    ".format(nmv.shape[1])\n",
    "\n",
    "nmv = secom.dropna(axis=0)\n",
    "print 'No. of rows after removing rows with missing data: {}'\\\n",
    ".format(nmv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEZCAYAAAC5AHPcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119cb3f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# num of missing entries per column\n",
    "\n",
    "m = map(lambda x: sum(secom[x].isnull()), xrange(secom.shape[1]))\n",
    "\n",
    "# distribution of columns with missing entries\n",
    "plt.hist(m, color='turquoise')\n",
    "plt.title(\"Distribution of missing values\")\n",
    "plt.xlabel(\"No. of missing values in a column\")\n",
    "plt.ylabel(\"Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of columns with more than 700 missing values: 32\n",
      "The number of columns with more than 200 missing values: 52\n"
     ]
    }
   ],
   "source": [
    "m_700thresh = filter(lambda i: (m[i] > 700), xrange(secom.shape[1]))\n",
    "print 'The number of columns with more than 700 missing values: {}'\\\n",
    ".format(len(m_700thresh))\n",
    "m_200thresh = filter(lambda i: (m[i] > 200), xrange(secom.shape[1]))\n",
    "print 'The number of columns with more than 200 missing values: {}'\\\n",
    ".format(len(m_200thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of columns after dropping columns with more than 200 missing entries: 520\n"
     ]
    }
   ],
   "source": [
    "# remove columns with more than 200 missing entries\n",
    "\n",
    "secom_drop_200thresh = secom.dropna(subset=[m_200thresh], axis=1)\n",
    "print 'No. of columns after dropping columns with more than 200 missing entries: {}'\\\n",
    ".format(secom_drop_200thresh.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 111 columns which have identical values recorded. We will drop these.\n",
      "The data set now has 409 columns.\n"
     ]
    }
   ],
   "source": [
    "# remove columns where every entry is identical (the std. dev = 0)\n",
    "\n",
    "dropthese = [x for x in secom_drop_200thresh.columns.values \\\n",
    "             if secom_drop_200thresh[x].std() == 0]\n",
    "\n",
    "print 'There are {} columns which have identical values recorded. \\\n",
    "We will drop these.' .format(len(dropthese))\n",
    "\n",
    "secom_drop_200thresh.drop(dropthese, axis=1, inplace=True)\n",
    "print 'The data set now has {} columns.'\\\n",
    ".format(secom_drop_200thresh.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of categorical variables is: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>576</th>\n",
       "      <th>577</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6765</td>\n",
       "      <td>14.9509</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1065</td>\n",
       "      <td>10.9003</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.006</td>\n",
       "      <td>208.2045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 409 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1          2          3       4         6       8       9    \\\n",
       "0  3030.93  2564.00  2187.7333  1411.1265  1.3602   97.6133  1.5005  0.0162   \n",
       "1  3095.78  2465.14  2230.4222  1463.6606  0.8294  102.3433  1.4966 -0.0005   \n",
       "\n",
       "      10      11     ...        576      577     582     583     584     585  \\\n",
       "0 -0.0034  0.9455    ...     1.6765  14.9509  0.5005  0.0118  0.0035  2.3630   \n",
       "1 -0.0148  0.9627    ...     1.1065  10.9003  0.5019  0.0223  0.0055  4.4447   \n",
       "\n",
       "      586     587    588       589  \n",
       "0     NaN     NaN    NaN       NaN  \n",
       "1  0.0096  0.0201  0.006  208.2045  \n",
       "\n",
       "[2 rows x 409 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking whether there is a mix of categorical variables\n",
    "\n",
    "print 'The number of categorical variables is: {}'\\\n",
    ".format(sum((secom_drop_200thresh.dtypes == 'categorical')*1))\n",
    "secom_drop_200thresh.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imputing missing values for the random forest\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "secom_imp = pd.DataFrame(imp.fit_transform(secom_drop_200thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Random Forest Variable Importance</h3>\n",
    "\n",
    "In addition to prediction the Random Forest can also be used to assess variable importance. In the <i>sklearn</i> [RandomForestClassifier](http://scikit-learn.org/stable/modules/ensemble.html#forest) package this is computed from the total decrease in node impurity when a  predictor is split. There are issues with this computation (there is a bias towards variables with more categories and correlated variables are arbitrarily selected) but we can ignore these since we will be using many variables for the OCSVM classifier. A bigger concern is the imbalance in the data set as this might affect the variable importance ranking.<br>\n",
    "\n",
    "The SECOM matrix at this point has 409 variables. We will use the Random Forest to rank the variables in terms of their importance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=7, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=7)\n",
    "rf.fit(secom_imp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Rank:\n",
      "  1 column   55  0.0155\n",
      "  2 column   50  0.0128\n",
      "  3 column  311  0.0113\n",
      "  4 column   56  0.0082\n",
      "  5 column   34  0.0077\n",
      "  6 column  351  0.0074\n",
      "  7 column  131  0.0070\n",
      "  8 column   21  0.0069\n",
      "  9 column  219  0.0065\n",
      " 10 column   85  0.0062\n",
      " 11 column   65  0.0061\n",
      " 12 column  230  0.0061\n",
      " 13 column  232  0.0059\n",
      " 14 column  310  0.0059\n",
      " 15 column  382  0.0058\n",
      "\n",
      "\n",
      "405 column  175  0.0000\n",
      "406 column  261  0.0000\n",
      "407 column  264  0.0000\n",
      "408 column  352  0.0000\n",
      "409 column   62  0.0000\n",
      "The number of features better than average is: 148\n"
     ]
    }
   ],
   "source": [
    "# displaying features and their rank\n",
    "\n",
    "importance = rf.feature_importances_\n",
    "ranked_indices = np.argsort(importance)[::-1]\n",
    "\n",
    "print \"Feature Rank:\"\n",
    "for i in range(15):\n",
    "    print \"{0:3d} column  {1:3d}  {2:6.4f}\"\\\n",
    "    .format(i+1, ranked_indices[i], importance[ranked_indices[i]])\n",
    "print \"\\n\"\n",
    "for i in xrange(len(importance)-5,len(importance)):\n",
    "    print \"{0:3d} column  {1:3d}  {2:6.4f}\"\\\n",
    "    .format(i+1, ranked_indices[i], importance[ranked_indices[i]])\n",
    "\n",
    "navg = 0\n",
    "for i in range(len(importance)):    \n",
    "    if importance[ranked_indices[i]] > np.average(rf.feature_importances_):\n",
    "        navg = navg+1\n",
    "print 'The number of features better than average is: {}'.format(navg)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAGJCAYAAADxMfswAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBt1OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1108dc110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of importance vs the number of features\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(len(importance)), importance[ranked_indices[:]])\n",
    "plt.axvline(15, color='magenta', linestyle='dashdot', label='n=15')\n",
    "plt.axvline(40, color='orange', linestyle='dashed', label='n=40')\n",
    "plt.axvline(65, color='turquoise', linestyle='dashdot', label='n=65')\n",
    "plt.axvline(100, color='red', linestyle='dotted', label='n=100')\n",
    "plt.text(15, 0.002, 'n=15', rotation='vertical')\n",
    "plt.text(40, 0.008, 'n=40', rotation='vertical')\n",
    "plt.text(65, 0.011, 'n=65', rotation='vertical')\n",
    "plt.text(100, 0.014, 'n=100', rotation='vertical')\n",
    "plt.title('Importance vs feature rank')\n",
    "plt.xlabel('feature rank')\n",
    "plt.ylabel('importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot, we see points of inflection around the 15, 40, 65 and 100 mark. We will use these to generate 4-5 sets of features to test out on the one-class SVM.  The 50 percentile mark is at 148 so these are reduced feature sets, much smaller than the 409 features we had after cleaning the data. In some of the literature <a href=\"#ref1\">[1]</a> associated with this data set, 40 features were used in the analysis. This was determined by correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> One-class SVM (OCSVM) </h3>\n",
    "\n",
    "The OCSVM proposed by Schölkopf et al. <a href=\"#ref2\">[2]</a>, <a href=\"#ref3\">[3]</a> can be used to detect negative examples in imbalanced data sets. In the OCSVM, training examples from the majority class are mapped to a feature space circumscribed by a hypersphere; a soft-margin decision boundary is minimized and all points outside are considered outliers. \n",
    "\n",
    "<h4>Preprocessing</h4>  \n",
    "\n",
    "The data is first divided into a majority class train and test set and the minority class test-only set.\n",
    "The OCSVM is sensitive to feature scale so the first step is to center and normalize the data. The train and test sets are scaled separately using the mean and variance computed from the training data. This is done to estimate the ability of the model to generalize.  \n",
    "\n",
    "<h4>Parameter Tuning</h4> \n",
    "\n",
    "The main parameters are the choice of the <i>kernel</i>, <i>nu</i> and <i>gamma</i>. Some preliminary evaluation showed that the linear and polynomial kernels give poor results. This leaves the <i>rbf</i> kernel for further experimentation.\n",
    "\n",
    "The hyper-parameters for OCSVM with the <i>rbf</i> kernel are nu ($\\nu$) and gamma ($\\gamma$).<br>\n",
    "<ul>\n",
    "<li> <b>nu:</b> the upper bound for the fraction of margin errors (outliers here) allowed in the data and the lower bound for support vectors relative to the total training examples. It has a range of (0,1). The OCSVM nu can be likened to the SVM parameter <i>C</i> in that both are attached to the penalty term of their respective objective functions.\n",
    "    <ol>\n",
    "    <li>Small nu is associated with a smaller margin and higher variance\n",
    "    <li>Large nu is associated with lower misclassification penalty and low model complexity\n",
    "    </ol>    \n",
    "<li> <b>gamma:</b> This is a regularization parameter which for the <i>rbf</i> kernel is equal to $\\frac{1}{2\\sigma^2}$. It defines the influence of a single training point on points nearby. \n",
    "    <ol>\n",
    "    <li> Low values of gamma (large $\\sigma$) imply that training points on or near the decision boundary have high influence. This tends to smoothen the decision boundary (as there are many points exerting an influence) and is related to higher bias. \n",
    "    <li> High values of gamma (small $\\sigma$) imply that points on the decision boundary exert less influence. This leads to a more flexible curvy decision boundary that is associated with higher variance.\n",
    "    </ol>    \n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for preprocessing, classification, parameter grid search \n",
    "\n",
    "def ocsvm_classify(nfeatures, param_grid, printflag=0, printheader=0):\n",
    "    \n",
    "    # selecting features and generating a data set\n",
    "    X_ocsvm   = secom_imp.loc[y == -1,ranked_indices[:nfeatures]]\n",
    "    X_outlier = secom_imp.loc[y == 1,ranked_indices[:nfeatures]]\n",
    "    if printflag:\n",
    "        print \"The majority/minority classes have {}/{} observations. \\n\"\\\n",
    "              .format(X_ocsvm.shape[0], X_outlier.shape[0]) \n",
    "\n",
    "    # By convention the majority class has a +1 label\n",
    "    # and the train and test set belong to the majority class.\n",
    "    # This is not to be confused with the secom dataset where \n",
    "    # the majority class has a -1 label\n",
    "    y_ocsvm = np.ones(len(X_ocsvm))\n",
    "    X_train, X_test, y_train, y_test = tts(\n",
    "    X_ocsvm, y_ocsvm, test_size=0.3, random_state=5)\n",
    "    \n",
    "    \n",
    "    # scaling the split data. The test/outlier data uses scaling parameters \n",
    "    # computed from the training data\n",
    "    standard_scaler = StandardScaler()\n",
    "    X_train_scaled  = standard_scaler.fit_transform(X_train)\n",
    "    X_test_scaled   = standard_scaler.transform(X_test)\n",
    "    X_outlier_scaled  = standard_scaler.transform(X_outlier)\n",
    "    \n",
    "    \n",
    "    # classify for each set of parameters in the grid\n",
    "    for i in range(len(list(ParameterGrid(param_grid)) )):\n",
    "        nu = ParameterGrid(param_grid)[i]['nu']\n",
    "        gamma = ParameterGrid(param_grid)[i]['gamma']\n",
    "        clf = svm.OneClassSVM(nu=nu, kernel='rbf', gamma=gamma)\n",
    "        clf.fit(X_train_scaled)\n",
    "        y_pred_train = clf.predict(X_train_scaled)\n",
    "        y_pred_test = clf.predict(X_test_scaled)\n",
    "        y_pred_outlier = clf.predict(X_outlier_scaled)\n",
    "        \n",
    "        # calculating error\n",
    "        n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "        n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "        n_error_outlier = y_pred_outlier[y_pred_outlier == 1].size   \n",
    "    \n",
    "        # printing results\n",
    "        if i == 0:\n",
    "            if printheader:\n",
    "                print \"nfeatures\\tnu\\tgamma\\t train error\\t test error\\t outlier error\"\n",
    "            print \"{0:3d}\\t\\t{1:3.2f}\\t{2:3.2f}\\t {3:3d}({4:4.2f}%)\\t {5:3d}({6:4.2f}%)\\t{7:3d}({8:4.2f}%)\"\\\n",
    "            .format(nfeatures, nu, gamma, \\\n",
    "            n_error_train, round(n_error_train/len(y_train) *100, 2),\\\n",
    "            n_error_test, round(n_error_test/len(y_test) *100, 2),\\\n",
    "            n_error_outlier, round(n_error_outlier/len(X_outlier) *100, 2))\n",
    "        else:\n",
    "            print \"\\t\\t{0:3.2f}\\t{1:3.2f}\\t {2:3d}({3:4.2f}%) \\t {4:3d}({5:4.2f}%)\\t{6:3d}({7:4.2f}%)\"\\\n",
    "            .format(nu, gamma, \\\n",
    "            n_error_train, round(n_error_train/len(y_train) *100, 2),\\\n",
    "            n_error_test, round(n_error_test/len(y_test) *100, 2),\\\n",
    "            n_error_outlier, round(n_error_outlier/len(X_outlier) *100, 2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority/minority classes have 1463/104 observations. \n",
      "\n",
      "nfeatures\tnu\tgamma\t train error\t test error\t outlier error\n",
      " 40\t\t0.03\t0.07\t 147(14.36%)\t 112(25.51%)\t 44(42.31%)\n",
      "\t\t0.04\t0.07\t 124(12.11%) \t 112(25.51%)\t 44(42.31%)\n",
      "\t\t0.05\t0.07\t 135(13.18%) \t 112(25.51%)\t 44(42.31%)\n",
      "\t\t0.03\t0.08\t 157(15.33%) \t 127(28.93%)\t 40(38.46%)\n",
      "\t\t0.04\t0.08\t 203(19.82%) \t 127(28.93%)\t 40(38.46%)\n",
      "\t\t0.05\t0.08\t 193(18.85%) \t 127(28.93%)\t 40(38.46%)\n",
      "\t\t0.03\t0.09\t 169(16.50%) \t 148(33.71%)\t 32(30.77%)\n",
      "\t\t0.04\t0.09\t 208(20.31%) \t 148(33.71%)\t 32(30.77%)\n",
      "\t\t0.05\t0.09\t 217(21.19%) \t 148(33.71%)\t 32(30.77%)\n",
      "\t\t0.03\t0.10\t 203(19.82%) \t 175(39.86%)\t 29(27.88%)\n",
      "\t\t0.04\t0.10\t 186(18.16%) \t 175(39.86%)\t 29(27.88%)\n",
      "\t\t0.05\t0.10\t 236(23.05%) \t 175(39.86%)\t 29(27.88%)\n",
      "\t\t0.03\t0.15\t 374(36.52%) \t 283(64.46%)\t 11(10.58%)\n",
      "\t\t0.04\t0.15\t 373(36.43%) \t 283(64.46%)\t 11(10.58%)\n",
      "\t\t0.05\t0.15\t 262(25.59%) \t 283(64.46%)\t 11(10.58%)\n",
      "\t\t0.03\t0.20\t 396(38.67%) \t 376(85.65%)\t  1(0.96%)\n",
      "\t\t0.04\t0.20\t 484(47.27%) \t 375(85.42%)\t  1(0.96%)\n",
      "\t\t0.05\t0.20\t 508(49.61%) \t 375(85.42%)\t  1(0.96%)\n",
      "\n",
      "\n",
      " 60\t\t0.10\t0.04\t 146(14.26%)\t 100(22.78%)\t 50(48.08%)\n",
      "\t\t0.20\t0.04\t 210(20.51%) \t 106(24.15%)\t 41(39.42%)\n",
      "\t\t0.10\t0.05\t 183(17.87%) \t 133(30.30%)\t 34(32.69%)\n",
      "\t\t0.20\t0.05\t 224(21.88%) \t 135(30.75%)\t 34(32.69%)\n",
      "\t\t0.10\t0.06\t 231(22.56%) \t 173(39.41%)\t 24(23.08%)\n",
      "\t\t0.20\t0.06\t 246(24.02%) \t 173(39.41%)\t 24(23.08%)\n",
      " 65\t\t0.10\t0.04\t 121(11.82%)\t 117(26.65%)\t 39(37.50%)\n",
      "\t\t0.10\t0.05\t 162(15.82%) \t 154(35.08%)\t 29(27.88%)\n",
      "100\t\t0.04\t0.03\t 208(20.31%)\t 159(36.22%)\t 29(27.88%)\n",
      "\t\t0.05\t0.03\t 212(20.70%) \t 159(36.22%)\t 29(27.88%)\n",
      "\t\t0.04\t0.04\t 275(26.86%) \t 237(53.99%)\t 14(13.46%)\n",
      "\t\t0.05\t0.04\t 259(25.29%) \t 237(53.99%)\t 14(13.46%)\n",
      "\n",
      "\n",
      " 15\t\t0.02\t0.10\t  56(5.47%)\t  42(9.57%)\t 73(70.19%)\n",
      "\t\t0.03\t0.10\t  57(5.57%) \t  42(9.57%)\t 73(70.19%)\n",
      "\t\t0.04\t0.10\t  63(6.15%) \t  42(9.57%)\t 73(70.19%)\n",
      "\t\t0.02\t0.15\t  85(8.30%) \t  62(14.12%)\t 59(56.73%)\n",
      "\t\t0.03\t0.15\t  83(8.11%) \t  62(14.12%)\t 59(56.73%)\n",
      "\t\t0.04\t0.15\t  95(9.28%) \t  62(14.12%)\t 59(56.73%)\n",
      "\t\t0.02\t0.18\t  98(9.57%) \t  81(18.45%)\t 52(50.00%)\n",
      "\t\t0.03\t0.18\t 105(10.25%) \t  80(18.22%)\t 52(50.00%)\n",
      "\t\t0.04\t0.18\t 107(10.45%) \t  81(18.45%)\t 52(50.00%)\n",
      "\t\t0.02\t0.20\t 120(11.72%) \t  90(20.50%)\t 49(47.12%)\n",
      "\t\t0.03\t0.20\t 126(12.30%) \t  91(20.73%)\t 49(47.12%)\n",
      "\t\t0.04\t0.20\t 125(12.21%) \t  91(20.73%)\t 49(47.12%)\n"
     ]
    }
   ],
   "source": [
    "# running a second pass on the tuning matrix (after a coarse first pass)\n",
    "\n",
    "param_grid = {'nu': [0.03,0.04,0.05], 'gamma': [0.07, 0.08, 0.09, 0.10, 0.15, 0.20]}\n",
    "ocsvm_classify(40, param_grid, printflag=1, printheader=1)\n",
    "print \"\\n\"\n",
    "param_grid = {'nu': [0.1,0.2], 'gamma': [0.04, 0.05, 0.06]}\n",
    "ocsvm_classify(60, param_grid)  \n",
    "param_grid = {'nu': [0.1], 'gamma': [0.04, 0.05]}\n",
    "ocsvm_classify(65, param_grid)\n",
    "param_grid = {'nu': [0.04,0.05], 'gamma': [0.03, 0.04]}\n",
    "ocsvm_classify(100, param_grid)\n",
    "print \"\\n\"\n",
    "param_grid = {'nu': [0.02,0.03, 0.04], 'gamma': [0.10, 0.15, 0.18, 0.20]}\n",
    "ocsvm_classify(15, param_grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Observations</h3>\n",
    "\n",
    "As gamma increases:\n",
    "*   the outlier classification improves\n",
    "*   the test error also improves \n",
    "*   the train error is not significantly affected\n",
    "\n",
    "As nu increases:\n",
    "*   the outlier and test error do not change\n",
    "*   the training error changes slightly increasing in some cases, decreasing in others\n",
    "\n",
    "As n, the number of variables, increases:\n",
    "*   n = 15, train error is much smaller than the outlier error\n",
    "*   n = 40 - 65: this seems to be the most tunable regime. The best results were obtained when the test error and outlier error were in the low 30% range when n=60 and 65.\n",
    "*   n = 100: This is also in the tunable range. \n",
    "\n",
    "<h3>Discussion</h3>\n",
    "\n",
    "This parameter grid search was carried out on a single split of the data (rather than cross-validation) but there is an  indication the models have high bias since the train error and test error are both high and also because you can reduce the outlier error by increasing the variance via gamma. \n",
    "\n",
    "The best<sup>**</sup> results were obtained when the test error and outlier error were in the low 30% range for n=40 - 65. \n",
    "\n",
    "| nfeatures   |      nu      | gamma | train error | test error |outlier error |           \n",
    "|:----------: |:------------:|:-----:|:----------: |:----------:|:----------:  |        \n",
    "|40 |0.03  | 0.09  | 169(16.50%)  |\t148(33.71%) |  32(30.77%)|\n",
    "|60 |0.10  | 0.05  | 183(17.87%)  | 133(30.30%) |  34(32.69%)| \n",
    "|65 |0.10  | 0.05  |162(15.82%)   |\t154(35.08%) | 29(27.88%) |\n",
    "\n",
    "This however is still too high. The OCSVM on this data set also appears to be difficult to tune so rather than find the optimal hyperparameters through cross-validation we will look at other classification methods. \n",
    "\n",
    "<sup>**</sup>Depending on which point in the production flow the data was recorded, one may wish to optimize for False Positives or False Negatives. If you optimize for detecting False Positives early in the production flow, you will  save resources for a device that will be dead in the backend. At the end of the line, detecting false negatives is more important since the chip, which increases in value with each process step, is most valuable at this stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> References and Further Reading </h3>\n",
    "\n",
    "<a name=\"ref1\"></a>[1] [M McCann Y Li L Maguire and A Johnston. \"Causality Challenge: Benchmarking relevant signal components for effective monitoring and process control.\" J. Mach. Learn. Res. Proc. NIPS 2008 workshop on causality](http://www.jmlr.org/proceedings/papers/v6/mccann10a/mccann10a.pdf).\n",
    "\n",
    "<a name=\"ref2\"></a>[2] [Schölkopf, Bernhard, et al. \"Support Vector Method for Novelty Detection.\" NIPS. Vol. 12. 1999.](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.675.575&rep=rep1&type=pdf)\n",
    "\n",
    "<a name=\"ref2\"></a>[3] [B. Schölkopf, A. Smola, R. Williamson, and P. L. Bartlett. New support vector algorithms. Neural Computation, 12, 2000, 1207-1245.](http://sci2s.ugr.es/keel/pdf/algorithm/articulo/NewSVM.pdf)\n",
    "\n",
    "[4] [Statnikov, Alexander, et al. \"A Gentle Introduction to Support Vector Machines in Biomedicine.\"](https://www.stat.auckland.ac.nz/~lee/760/SVM%20tutorial.pdf)\n",
    "\n",
    "[5] [SVM Parameters](http://www.svms.org/parameters/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FAAC58; margin-left: 0px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px;\">\n",
    "\n",
    "\n",
    "Author:  Meena Mani  <br>\n",
    "email:   meenas.mailbag@gmail.com   <br> \n",
    "twitter: @meena_uvaca    <br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
